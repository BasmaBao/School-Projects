{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTqeYS84_iz6"
   },
   "source": [
    "# Lab 6.1 : Using Lime with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ck4we8Dt_iz_"
   },
   "source": [
    "In this tutorial we will show how to use Lime framework with Pytorch. We will use Lime to explain the prediction generated by one of the pretrained ImageNet models.\n",
    "\n",
    "Let's start with importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9309,
     "status": "ok",
     "timestamp": 1674382000425,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "XroTP_oqEzhg",
    "outputId": "8ac9f42a-78cc-42f3-862a-fd0db3c043ed"
   },
   "outputs": [],
   "source": [
    "# Install LIME package\n",
    "# On Google Colab\n",
    "!pip install lime\n",
    "# On your personal laptop with Anaconda\n",
    "# conda install -c conda-forge lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4757,
     "status": "ok",
     "timestamp": 1674382005180,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "kdWkOhVo_i0B",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os, json\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1674382005180,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "-syuHb2f0zbw",
    "outputId": "f42c889f-ef36-494d-d276-741759d54ced"
   },
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1974,
     "status": "ok",
     "timestamp": 1674382007133,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "elVBTp6gAPMr",
    "outputId": "87ec2aa2-084f-49be-bc9c-90f046879ef3"
   },
   "outputs": [],
   "source": [
    "# Download the image and the class index\n",
    "# You can alternatively use \"wget\"\n",
    "!curl https://raw.githubusercontent.com/marcotcr/lime/master/doc/notebooks/data/imagenet_class_index.json --output imagenet_class_index.json \n",
    "!curl https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n02085620_Chihuahua.JPEG --output dog.png\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674382007133,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "-EHU3N4v7prv",
    "outputId": "fef72984-8ad9-49ad-9ee9-63a1ab8253dc"
   },
   "outputs": [],
   "source": [
    "# The following code loads json file. The output will have values of dict type.\n",
    "file_name_imagenet_class = \"imagenet_class_index.json\"\n",
    "with open(file_name_imagenet_class, 'r') as f:\n",
    "    class_idx =  json.loads(f.read())\n",
    "    \n",
    "# Print the class names\n",
    "for c in class_idx.values():\n",
    "    print(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXBITExSZMp1"
   },
   "source": [
    "### Question 1: What is ImageNet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk2cHgMl1qA1"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "The ImageNet project is a large visual database designed for use in visual object recognition software research. More than 14 million images have been hand-annotated by the project to indicate what objects are pictured and in at least one million of the images, bounding boxes are also provided.\n",
    "\n",
    "ImageNet is a large collection of images, labeled against WordNet 3.0 and described at http://image-net.org/. \n",
    "WordNet is a lexical database of semantic relations between words in more than 200 languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmHlJ5Osai-z"
   },
   "source": [
    "### Question 2: What is Inception ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS5nAgbFCeLa"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "Inception-v3 is a convolutional neural network architecture from the Inception family.\n",
    "\n",
    "Inception-v3 is a convolutional neural network that is 48 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. As a result, the network has learned rich feature representations for a wide range of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9bBb4xr_i0I"
   },
   "source": [
    "Load our test image and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 1607,
     "status": "ok",
     "timestamp": 1674382008737,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "9ATWUmma_i0K",
    "outputId": "c2bcb22d-4641-464c-caf5-29f5b794803c"
   },
   "outputs": [],
   "source": [
    "def get_image(path):\n",
    "    with open(os.path.abspath(path), 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB') \n",
    "        \n",
    "img = get_image('dog.png')\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0y7FLLEn_i0Q"
   },
   "source": [
    "We need to convert this image to Pytorch tensor and also apply whitening as used by our pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674382008737,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "ax2YktVQ_i0S"
   },
   "outputs": [],
   "source": [
    "# resize and take the center part of image to what our model expects\n",
    "def get_input_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])       \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_input_tensors(img):\n",
    "    transf = get_input_transform()\n",
    "    # unsqeeze converts single image to batch of 1\n",
    "    return transf(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZkAUJlJb301"
   },
   "source": [
    "### Question 3: Explain what is a pretrained model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uw3pE8msoZ33"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "The pretrained model is described on the Pytorch website\n",
    "\n",
    "https://pytorch.org/hub/pytorch_vision_inception_v3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "4c38596a740a409bbeefad1bbba4082b",
      "66b0381fecf44f54a0c0b0d3b895595e",
      "f3bcb954a184459f803aee2e4aa0a3d4",
      "c0205b7ee62141fa9340eb975dfc597d",
      "cf21281f81054eb88bf95659c3cdb382",
      "c3ab2a0c5b84485ea778edaec0b85982",
      "280e5c1bb3224378a583f1be96b2c012",
      "c9f0af986c7f488b952eaf488a760c27",
      "9eb9168ff8e84e3081512b73c597b344",
      "21542f828d2842979803976daf6e6a79",
      "f99df16be8d3498286a5aba5c23a5074"
     ]
    },
    "executionInfo": {
     "elapsed": 4169,
     "status": "ok",
     "timestamp": 1674382012896,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "6cmaX7wB_i0Y",
    "outputId": "40ec281e-27d9-44bb-d79a-8a85af2256fe"
   },
   "outputs": [],
   "source": [
    "model = models.inception_v3(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_220fTeDcNnv"
   },
   "source": [
    "### Question 4: How do we call the approach of using pretrained model for a new task ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMWI3pWG_i0X"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "We call it transfer learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCcBkpfAxSr9"
   },
   "source": [
    "### Question 5: Print the pretrained model. Analyse the architecture (How many layers? of which type? etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1674382012896,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "Uil-FDXeoZ33",
    "outputId": "cb86b905-8484-47f3-c7a8-839c4834ee1d"
   },
   "outputs": [],
   "source": [
    "# fill in this cell\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df0RhW4h_i0e"
   },
   "source": [
    "Load label texts for ImageNet predictions so we know what model is predicting\n",
    "\n",
    "The file 'imagenet_class_index.json' contains the mapping of ImageNet class id to ImageNet class name. We get the class name of the predicted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1674382012897,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "-FHXpRHn_i0g",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx2label, cls2label, cls2idx = [], {}, {}\n",
    "with open(os.path.abspath(file_name_imagenet_class), 'r') as read_file:\n",
    "    class_idx = json.load(read_file)\n",
    "    # Create the list of class labels\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "    cls2label = {class_idx[str(k)][0]: class_idx[str(k)][1] for k in range(len(class_idx))}\n",
    "    cls2idx = {class_idx[str(k)][0]: k for k in range(len(class_idx))}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNr9rdS1_i0l"
   },
   "source": [
    "Get the predicition for our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1674382012897,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "Y3t5y6gy_i0m"
   },
   "outputs": [],
   "source": [
    "img_t = get_input_tensors(img)\n",
    "model.eval()\n",
    "logits = model(img_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUMDSTtp3yEp"
   },
   "source": [
    "### Question 6: What is the meaning of Top N accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fbqBQ7foZ34"
   },
   "source": [
    "#### Answer:\n",
    "Top N accuracy is when you measure how often your predicted class falls in the top N values of your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yN0ulItm_i0q"
   },
   "source": [
    "Predicitions we got are logits. Let's pass that through softmax to get probabilities and class labels for top 5 accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1674382012897,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "QK5e7c-X_i0s",
    "outputId": "5c65d577-9129-4cff-98a1-d21c31d8bb27"
   },
   "outputs": [],
   "source": [
    "probs = F.softmax(logits, dim=1)\n",
    "probs5 = probs.topk(5)\n",
    "tuple((p,c, idx2label[c]) for p, c in zip(probs5[0][0].detach().numpy(), probs5[1][0].detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UM-bza4D_i0x"
   },
   "source": [
    "We are getting ready to use Lime. Lime produces the array of images from original input image by pertubation algorithm. So we need to provide two things: (1) original image as numpy array (2) classification function that would take array of purturbed images as input and produce the probabilities for each class for each image as output. \n",
    "\n",
    "For Pytorch, first we need to define two separate transforms: (1) to take PIL image, resize and crop it (2) take resized, cropped image and apply whitening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1674382012897,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "GLDoaamV_i0y"
   },
   "outputs": [],
   "source": [
    "def get_pil_transform(): \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224)\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_preprocess_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])     \n",
    "    transf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf    \n",
    "\n",
    "pill_transf = get_pil_transform()\n",
    "preprocess_transform = get_preprocess_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEo1T_PH_i03"
   },
   "source": [
    "Now we are ready to define classification function that Lime needs. The input to this function is numpy array of images where each image is ndarray of shape (channel, height, width). The output is numpy array of shape (image index, classes) where each value in array should be probability for that image, class combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1674382012897,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "IitvLmKr_i04"
   },
   "outputs": [],
   "source": [
    "def batch_predict(images):\n",
    "    model.eval()\n",
    "    batch = torch.stack(tuple(preprocess_transform(i) for i in images), dim=0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    logits = model(batch)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    return probs.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViCQi8l9_i08"
   },
   "source": [
    "Let's test the function for the sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13921,
     "status": "ok",
     "timestamp": 1674382026814,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "cBkEDIjt_i0-",
    "outputId": "335f37eb-5f41-4601-db8e-8f37f6b1826b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_pred = batch_predict([pill_transf(img)])\n",
    "test_pred.squeeze().argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHx3m13t_i1B"
   },
   "source": [
    "Import lime and create explanation for this prediciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2024,
     "status": "ok",
     "timestamp": 1674382028817,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "bMy1NMzZ_i1D",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lime import lime_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7ac846e8e0e64d9db5f901779b7aaee4",
      "3de3c23cca414a0faa3414b7dd87609b",
      "fc5b1d3d343f40aab3c275f7f68cbe29",
      "cff789875c924da3a9525bc2bc663fb4",
      "3a569d8fd1f44188bbd00b728936e1fe",
      "943bd22db6044df4bd9db7baba1193ae",
      "e5bc2093ca214ba7bca149fc1465c325",
      "c076ccac29d34c8da854885b5ced780e",
      "413cef5fd1b24940a9f5d2c9bbb364bc",
      "c3819e6b86a84505bd5678bcefa8d273",
      "fc9002d2b8f249469e1dd2e87ceb0ed1"
     ]
    },
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1674382029567,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "zFsGUTr4_i1G",
    "outputId": "83e148bf-3372-40b3-dc43-824c8a096baf"
   },
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(np.array(pill_transf(img)), \n",
    "                                         batch_predict, # classification function\n",
    "                                         top_labels=5, \n",
    "                                         num_samples=100) # number of images that will be sent to classification function\n",
    "\n",
    "# The algorithm generates neighborhood data by randomly perturbing features from the instance. \n",
    "# It then learns locally weighted linear models on this neighborhood data to explain each of the classes \n",
    "# in an interpretable way.\n",
    "# num_samples – size of the neighborhood to learn the linear mode\n",
    "# top_labels – if not None, ignore labels and produce explanations for the K labels with highest prediction probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbOBKYW6_i1L"
   },
   "source": [
    "Let's use mask on image and see the areas that are encouraging the top prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1674382029568,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "7AJsxZAw_i1M"
   },
   "outputs": [],
   "source": [
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1674382029568,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "KYZ_ADtV_i1R",
    "outputId": "3a93a006-fd59-46f6-ea9b-d0e504fa7915",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], \n",
    "                                            positive_only=True, negative_only=False, \n",
    "                                            num_features=5, \n",
    "                                            hide_rest=True)\n",
    "# Parameters:\n",
    "# hide_rest – if True, make the non-explanation part of the return image gray\n",
    "# num_features – number of superpixels to include in explanation\n",
    "\n",
    "img_boundry1 = mark_boundaries(temp/255.0, mask)\n",
    "imgplot = plt.imshow(img_boundry1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBE_FC4c_i1V"
   },
   "source": [
    "Let's turn on areas that contributes against the top prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1674382030484,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "xkYGYth9_i1W",
    "outputId": "60fc1aaf-2c30-4a1c-e457-1b7c0972f843",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], \n",
    "                                            positive_only=False, negative_only=True,\n",
    "                                            num_features=5, \n",
    "                                            hide_rest=True)\n",
    "img_boundry2 = mark_boundaries(temp/255.0, mask)\n",
    "imgplot = plt.imshow(img_boundry2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIieng9_5hHj"
   },
   "source": [
    "Let's turn on both positive and negative areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674382030484,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "oUmEEwkG5ikj",
    "outputId": "c2d7a77e-327b-4881-ec2d-148dcc1e8d1a"
   },
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], \n",
    "                                            positive_only=False, negative_only=False,\n",
    "                                            num_features=100, \n",
    "                                            hide_rest=True)\n",
    "img_boundry3 = mark_boundaries(temp/255.0, mask)\n",
    "imgplot = plt.imshow(img_boundry3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "21542f828d2842979803976daf6e6a79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "280e5c1bb3224378a583f1be96b2c012": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a569d8fd1f44188bbd00b728936e1fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3de3c23cca414a0faa3414b7dd87609b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_943bd22db6044df4bd9db7baba1193ae",
      "placeholder": "​",
      "style": "IPY_MODEL_e5bc2093ca214ba7bca149fc1465c325",
      "value": "100%"
     }
    },
    "413cef5fd1b24940a9f5d2c9bbb364bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c38596a740a409bbeefad1bbba4082b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66b0381fecf44f54a0c0b0d3b895595e",
       "IPY_MODEL_f3bcb954a184459f803aee2e4aa0a3d4",
       "IPY_MODEL_c0205b7ee62141fa9340eb975dfc597d"
      ],
      "layout": "IPY_MODEL_cf21281f81054eb88bf95659c3cdb382"
     }
    },
    "66b0381fecf44f54a0c0b0d3b895595e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3ab2a0c5b84485ea778edaec0b85982",
      "placeholder": "​",
      "style": "IPY_MODEL_280e5c1bb3224378a583f1be96b2c012",
      "value": "100%"
     }
    },
    "7ac846e8e0e64d9db5f901779b7aaee4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3de3c23cca414a0faa3414b7dd87609b",
       "IPY_MODEL_fc5b1d3d343f40aab3c275f7f68cbe29",
       "IPY_MODEL_cff789875c924da3a9525bc2bc663fb4"
      ],
      "layout": "IPY_MODEL_3a569d8fd1f44188bbd00b728936e1fe"
     }
    },
    "943bd22db6044df4bd9db7baba1193ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eb9168ff8e84e3081512b73c597b344": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0205b7ee62141fa9340eb975dfc597d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21542f828d2842979803976daf6e6a79",
      "placeholder": "​",
      "style": "IPY_MODEL_f99df16be8d3498286a5aba5c23a5074",
      "value": " 104M/104M [00:04&lt;00:00, 23.5MB/s]"
     }
    },
    "c076ccac29d34c8da854885b5ced780e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3819e6b86a84505bd5678bcefa8d273": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3ab2a0c5b84485ea778edaec0b85982": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9f0af986c7f488b952eaf488a760c27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf21281f81054eb88bf95659c3cdb382": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cff789875c924da3a9525bc2bc663fb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3819e6b86a84505bd5678bcefa8d273",
      "placeholder": "​",
      "style": "IPY_MODEL_fc9002d2b8f249469e1dd2e87ceb0ed1",
      "value": " 100/100 [00:00&lt;00:00, 143.95it/s]"
     }
    },
    "e5bc2093ca214ba7bca149fc1465c325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3bcb954a184459f803aee2e4aa0a3d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9f0af986c7f488b952eaf488a760c27",
      "max": 108949747,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9eb9168ff8e84e3081512b73c597b344",
      "value": 108949747
     }
    },
    "f99df16be8d3498286a5aba5c23a5074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc5b1d3d343f40aab3c275f7f68cbe29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c076ccac29d34c8da854885b5ced780e",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_413cef5fd1b24940a9f5d2c9bbb364bc",
      "value": 100
     }
    },
    "fc9002d2b8f249469e1dd2e87ceb0ed1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
