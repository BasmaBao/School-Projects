{"cells":[{"cell_type":"markdown","metadata":{"id":"Zt3nY3xZgC-Q"},"source":["# Lab 3: Neural Tangent Kernel\n","\n","The goal of this lab is to compute by hand a neural tangent kernel."]},{"cell_type":"markdown","metadata":{"id":"VMoz9H5VuC5B"},"source":["## Non-linear regression with a neural network"]},{"cell_type":"markdown","metadata":{"id":"DDMmHyHmJfRC"},"source":["Generate the dataset and visualize it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0X-XnJAPHN-Q"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import torch\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z70NGe6nHN-R","executionInfo":{"status":"ok","timestamp":1671214673162,"user_tz":-60,"elapsed":5,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"f5a624af-a445-4bc0-dfd5-853dc1324d8c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f74929a4150>"]},"metadata":{},"execution_count":2}],"source":["random_seed = 3455\n","torch.manual_seed(random_seed)"]},{"cell_type":"markdown","metadata":{"id":"YakqohgqHN-R"},"source":["### Question 1: generate the training samples.\n","\n","Generate $N=4$ values $x_i$'s in $[-35,35]$ that are uniformly distributed. Generate the labels $y_i$ such that\n","\n","$$\n","y_i = sigmoid(w^* x_i)\n","$$\n","\n","with $w^*=0.1$ and \"sigmoid\" is the sigmoid function $\\sigma(t)=1/(1+e^{-t})$.\n","\n","Generate $N$ other samples that will be used as a test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tt4ev-c2HN-S"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"DzyK8JI1HN-S"},"source":["### Question 2: plot the training samples."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"cgX95GsNHN-T"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"CkcyFiacL8fH"},"source":["## Implementation of the Neural network"]},{"cell_type":"markdown","metadata":{"id":"h7CeUDR6HN-T"},"source":["### Question 3: implement a ReLU neural network with a single hidden layer. You can use 100 hidden neurons. The goal of the neural network is to estimate the labels considered as some real values (it is a regression problem, not a classification one)."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"ChGMuFXGHN-T"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"pH5w46i4HN-U"},"source":["### Question 4: define an Adam optimizer and the appropriate loss function."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"0oaWLORJHN-U"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"Sb7cim5yHN-U"},"source":["## Train the neural network"]},{"cell_type":"markdown","metadata":{"id":"ha9FMUATHN-U"},"source":["### Question 5: train the neural network with the Adam optimizer."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"SilhAFs3HN-U"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"_IdiMkFIHN-U"},"source":["### Question 6: plot the training loss and the test loss. Comment briefly the convergence of the training. You can adjust the learning rate to improve the loss if necessary."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"A3MTKA_wHN-V"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"H5UQlaTQHN-V"},"source":["### Question 7: write a Pytorch function with inputs \"x\", \"y\" and \"y_pred\" that plots the predicted labels \"y_pred\" and the ground-truth labels \"y\" with respect to \"x\". The goal is to analyse visually the quality of the learning. Use this function two times to plot the neural network approximation for 1) the training samples and 2) the test samples."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"AJzMMM42HN-V"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"_LUKpWbaHN-V"},"source":["## Study of the NTK"]},{"cell_type":"markdown","metadata":{"id":"9aqqho33M21_"},"source":["### Question 8: use autograd to compute the Jacobian matrix that is necessary to compute the neural tangent kernel. You will write a function \"computeJacobian(x, model)\" whose inputs are \"x\" and the neural network model \"model\"."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"Aw8RozyaHN-V"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"DXrNq-SnHN-V"},"source":["### Question 9: compute the NTK matrix $K_0$ before the training. You can save the model before the training and load it here to compute the NTK."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"IuufqEWOHN-V"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"hidIO7toHN-V"},"source":["### Question 10: compute the NTK $K^*$ after the training."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"gnEUUI4qHN-W"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"UG8eHFwLHN-W"},"source":["### Question 11: check the difference between the NTK $K_0$ before the training and the NTK $K^*$ after the training. Compute the relative change between the NTK coefficients with respect to the Frobenius norm."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"9HqICDBQHN-W"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"IwIHYA5LHN-W"},"source":["### Question 12: use the feature $\\phi(x)$ deduced from the NTK $K_0$ to learn a kernel linear regression. The linear regression will be trained with sklearn \"LinearRegression()\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWBjZHdAHN-W"},"outputs":[],"source":["from sklearn import linear_model"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"ZJJo6oKCHN-W"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"xR1YvNY9HN-W"},"source":["### Question 13: Compare the results with the kernel linear regressions deduced from $K_0$ and $K^*$. You must train the two regression models and evaluate them with the training set."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"qXrHEzjNHN-W"},"outputs":[],"source":["# Complete the cell"]},{"cell_type":"markdown","metadata":{"id":"9Lrn6rqnHN-W"},"source":["### Question 14: Compare the results with the kernel linear regressions deduced from $K_0$ and $K^*$. You must evaluate them with the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"HOSweAfeHN-W"},"outputs":[],"source":["# Complete the cell"]}],"metadata":{"colab":{"provenance":[{"file_id":"1PVRPOeJYXYLFJik1D0klJ2djFnMzdA9L","timestamp":1578246214551},{"file_id":"1Oqqv39a5LSa4dzWn4XMmEdONAloY4ASC","timestamp":1570979627787},{"file_id":"1KOuMuh8RKiWRk9jswod-tvc9lGFTJS2T","timestamp":1570367072773}],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}