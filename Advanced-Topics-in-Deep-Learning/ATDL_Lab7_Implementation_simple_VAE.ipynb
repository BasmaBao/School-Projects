{"cells":[{"cell_type":"markdown","metadata":{"id":"siOWYj607EDp"},"source":["# First step to implement a Variational AutoEncoder (VAE)\n","\n","The main goal of this lab is to implement by hand the main steps of a VAE in Pytorch."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"VutHjNiGuCsp","executionInfo":{"status":"ok","timestamp":1706173106134,"user_tz":-60,"elapsed":9299,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","import torchvision.utils\n","import numpy as np\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"-7tA0n2t7e7d"},"source":["Definition of the most important constant values"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KPr3w8tcuCsu","executionInfo":{"status":"ok","timestamp":1706173106135,"user_tz":-60,"elapsed":5,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","BATCH_SIZE = 64         # number of data points in each batch\n","N_EPOCHS = 10           # times to run the model on complete data\n","INPUT_DIM = 28 * 28     # size of each input\n","HIDDEN_DIM = 256        # hidden dimension\n","LATENT_DIM = 2          # latent vector dimension\n","lr = 1e-3               # learning rate"]},{"cell_type":"markdown","metadata":{"id":"qlV8lwnP-OSr"},"source":["## Load the dataset"]},{"cell_type":"markdown","metadata":{"id":"j8EI7OSD7rMV"},"source":["Import the MNIST dataset.\n","\n","This dataset is described [here](https://en.wikipedia.org/wiki/MNIST_database)"]},{"cell_type":"markdown","metadata":{"id":"m2_IDCpq-Bp4"},"source":["### Question 1: what is the size of a MNIST image? Is it a color image?"]},{"cell_type":"markdown","metadata":{"id":"_Fc44xXskECA"},"source":["#### Answer:\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"bUahAYfNuCsy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706173108554,"user_tz":-60,"elapsed":2422,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"8e4cd401-b671-4b12-a887-a631707dd596"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 85261298.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 118181164.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 29686396.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 21143761.12it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["transforms = transforms.Compose([transforms.ToTensor()])\n","train_dataset = datasets.MNIST(\n","    './data',\n","    train=True,\n","    download=True,\n","    transform=transforms)\n","\n","test_dataset = datasets.MNIST(\n","    './data',\n","    train=False,\n","    download=True,\n","    transform=transforms\n",")"]},{"cell_type":"markdown","metadata":{"id":"9yZ3vUqp9zje"},"source":["### Question 2: what is the size of \"train_dataset\"?"]},{"cell_type":"markdown","metadata":{"id":"p-toulBjkECA"},"source":["#### Answer:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HaK-_fStA2UU"},"source":["### Question 3: plot the tenth image of the \"train_dataset\"? What is its label?"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"OgdAS_EUAa1T","executionInfo":{"status":"ok","timestamp":1706173108554,"user_tz":-60,"elapsed":6,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Fill in this cell\n"]},{"cell_type":"markdown","metadata":{"id":"RMgVYfhE8-j8"},"source":["### Question 4: how many batches are composing \"train_iterator\" in the following cell? What is the size of a batch?"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"BQ-uaEYwuCs1","executionInfo":{"status":"ok","timestamp":1706173108554,"user_tz":-60,"elapsed":4,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Ih3FMFak8s47","executionInfo":{"status":"ok","timestamp":1706173108554,"user_tz":-60,"elapsed":3,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Fill in this cell to anwser the question\n"]},{"cell_type":"markdown","metadata":{"id":"t6Xqi-ZJ-uIz"},"source":["## Implement the VAE"]},{"cell_type":"markdown","metadata":{"id":"fGVLh7AWDWBP"},"source":["### Question 5: describe carefully the architecture of the \"Encoder\". What are \"z_mu\" and \"z_var\"?"]},{"cell_type":"markdown","metadata":{"id":"ic5M6nFqkECB"},"source":["#### Answer:\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"hMaQqWr-uCs5","executionInfo":{"status":"ok","timestamp":1706173108897,"user_tz":-60,"elapsed":346,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    # This the encoder part of VAE\n","\n","    def __init__(self, input_dim, hidden_dim, z_dim):\n","        '''\n","        Args:\n","            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n","            hidden_dim: A integer indicating the size of hidden dimension.\n","            z_dim: A integer indicating the latent dimension.\n","        '''\n","        super().__init__()\n","\n","        self.linear = nn.Linear(input_dim, hidden_dim)\n","        self.mu = nn.Linear(hidden_dim, z_dim)\n","        self.var = nn.Linear(hidden_dim, z_dim)\n","\n","    def forward(self, x):\n","        # x is of shape [batch_size, input_dim]\n","\n","        hidden = F.relu(self.linear(x))\n","        # hidden is of shape [batch_size, hidden_dim]\n","        z_mu = self.mu(hidden)\n","        # z_mu is of shape [batch_size, latent_dim]\n","        z_var = self.var(hidden)\n","        # z_var is of shape [batch_size, latent_dim]\n","\n","        return z_mu, z_var\n"]},{"cell_type":"markdown","metadata":{"id":"9fuKNZyODpT8"},"source":["### Question 6: describe carefully the architecture of the \"Decoder\". Why are we using \"torch.sigmoid\"? What is \"predicted\"?"]},{"cell_type":"markdown","metadata":{"id":"260_X0V4kECC"},"source":["#### Answer:\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nVlKTe0huCs8","executionInfo":{"status":"ok","timestamp":1706173108897,"user_tz":-60,"elapsed":3,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["class Decoder(nn.Module):\n","    ''' This the decoder part of VAE\n","\n","    '''\n","    def __init__(self, z_dim, hidden_dim, output_dim):\n","        '''\n","        Args:\n","            z_dim: A integer indicating the latent size.\n","            hidden_dim: A integer indicating the size of hidden dimension.\n","            output_dim: A integer indicating the output dimension (in case of MNIST it is 28 * 28)\n","        '''\n","        super().__init__()\n","\n","        self.linear = nn.Linear(z_dim, hidden_dim)\n","        self.out = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        # x is of shape [batch_size, latent_dim]\n","\n","        hidden = F.relu(self.linear(x))\n","        # hidden is of shape [batch_size, hidden_dim]\n","\n","        predicted = torch.sigmoid(self.out(hidden))\n","        # predicted is of shape [batch_size, output_dim]\n","        return predicted\n","\n"]},{"cell_type":"markdown","metadata":{"id":"u1N-HaBnEP42"},"source":["### Question 7: complete the following class. You must add the commands to generate the latent variables \"z\" and to generate the \"predicted\" output.\n"]},{"cell_type":"markdown","metadata":{"id":"48hc0leCkECC"},"source":["#### Answer:\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"IFIoKKteuCtA","executionInfo":{"status":"ok","timestamp":1706173108897,"user_tz":-60,"elapsed":2,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["class VAE(nn.Module):\n","    def __init__(self, enc, dec):\n","        ''' This the VAE, which takes a encoder and decoder.\n","\n","        '''\n","        super().__init__()\n","\n","        self.enc = enc\n","        self.dec = dec\n","\n","    def forward(self, x):\n","\n","        # Fill in this forward function\n","        ...\n","\n","\n","\n","        return predicted, z_mu, z_var\n"]},{"cell_type":"markdown","metadata":{"id":"wHlA9OzfkECD"},"source":["Initialize all the components of the VAE."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"XHmHwKjVuCtE","executionInfo":{"status":"ok","timestamp":1706173109114,"user_tz":-60,"elapsed":219,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# encoder\n","encoder = Encoder(INPUT_DIM, HIDDEN_DIM, LATENT_DIM)\n","\n","# decoder\n","decoder = Decoder(LATENT_DIM, HIDDEN_DIM, INPUT_DIM)\n","\n","# vae\n","model = VAE(encoder, decoder).to(device)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vcJKhaWy5pJ9"},"source":["Print the number of parameters of the VAE"]},{"cell_type":"markdown","metadata":{"id":"1yaU_znmkECD"},"source":["### Question 8: what is the role of \"p.requires_grad\" in the following cell?"]},{"cell_type":"markdown","metadata":{"id":"MMMNiAuMkECD"},"source":["#### Answer:\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706173109115,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"},"user_tz":-60},"id":"2u8wQYlt5UlX","outputId":"423a5a2b-1762-43ef-ce6b-1068d3b738c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of parameters: 404244\n"]}],"source":["num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print('Number of parameters: %d' % num_params)"]},{"cell_type":"markdown","metadata":{"id":"IRegDPg2Fd2T"},"source":["## Train the VAE"]},{"cell_type":"markdown","metadata":{"id":"1BjQEcDYFbXC"},"source":["Define the optimizer"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"3PRqRa5vFadC","executionInfo":{"status":"ok","timestamp":1706173109115,"user_tz":-60,"elapsed":3,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# optimizer\n","optimizer = optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"markdown","metadata":{"id":"wtkZyq-uFkU0"},"source":["### Question 9: complete the following function \"train\" to train the VAE, i.e., you must compute the loss."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"YxoU0xKquCtI","executionInfo":{"status":"ok","timestamp":1706173109335,"user_tz":-60,"elapsed":222,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["def train():\n","    # set the train mode\n","    model.train()\n","\n","    # loss of the epoch\n","    train_loss = 0\n","\n","    for i, (x, _) in enumerate(train_iterator):\n","        # reshape the data into [batch_size, 784]\n","        x = x.view(-1, 28 * 28)\n","        x = x.to(device)\n","\n","        # update the gradients to zero\n","        optimizer.zero_grad()\n","\n","        # forward pass\n","        x_sample, z_mu, z_var = model(x)\n","\n","\n","        # Fill in this place to compute the two losses: recon_loss and kl_loss\n","        ...\n","\n","        # total loss\n","        # WARNING: Pytorch minimizes the loss. Hence, we compute the opposite of the loss given in the lecture!\n","        loss = recon_loss + kl_loss\n","\n","        # backward pass\n","        loss.backward()\n","        train_loss += loss.item()\n","\n","        # update the weights\n","        optimizer.step()\n","\n","    return train_loss\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xwHElg9mGkdo"},"source":["### Question 10: what is the role of \"model.eval()\" in the folllowing \"test\" function?"]},{"cell_type":"markdown","metadata":{"id":"Fw06CFF-kECE"},"source":["#### Answer:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pUsD7xk7Gwxu"},"source":["### Question 11: what is the role of \"torch.no_grad()\" in the folllowing \"test\" function?"]},{"cell_type":"markdown","metadata":{"id":"iZFSq9KNkECE"},"source":["#### Answer:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-6fPx2eNG7Q7"},"source":["### Question 12: complete the following function \"test\" to train the VAE, i.e., you must compute the loss. The answer is the same as for the training step."]},{"cell_type":"markdown","metadata":{"id":"ECAApKk-kECE"},"source":["#### Answer:\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"khU9f4j9uCtL","executionInfo":{"status":"ok","timestamp":1706173109336,"user_tz":-60,"elapsed":3,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["def test():\n","    # set the evaluation mode\n","    model.eval()\n","\n","    # test loss for the data\n","    test_loss = 0\n","\n","    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n","    with torch.no_grad():\n","        for i, (x, _) in enumerate(test_iterator):\n","            # reshape the data\n","            x = x.view(-1, 28 * 28)\n","            x = x.to(device)\n","\n","            # forward pass\n","            x_sample, z_mu, z_var = model(x)\n","\n","            # Fill in this place to compute the two losses: recon_loss and kl_loss\n","            ...\n","\n","            # total loss\n","            loss = recon_loss + kl_loss\n","            test_loss += loss.item()\n","\n","    return test_loss\n"]},{"cell_type":"markdown","metadata":{"id":"8Y9R1AmqI2ME"},"source":["### Question 13: What is the goal of the following cell? What is the role of \"if patience_counter > 3\"?"]},{"cell_type":"markdown","metadata":{"id":"Fb5UTaZpJqTZ"},"source":["#### Answer:\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"elapsed":242,"status":"error","timestamp":1706173109574,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"},"user_tz":-60},"id":"iHZc5MUduCtR","outputId":"cb8089cf-1b6e-4aa0-a51f-2a91f0bc4e84"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'predicted' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-182a1e614de8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-0683989f6770>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-f12e7d41cade>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'predicted' is not defined"]}],"source":["best_test_loss = float('inf')\n","\n","for e in range(1,N_EPOCHS+1):\n","\n","    train_loss = train()\n","    test_loss = test()\n","\n","    train_loss /= len(train_dataset)\n","    test_loss /= len(test_dataset)\n","\n","    print(f'Epoch {e}/{N_EPOCHS}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f}')\n","\n","    if best_test_loss > test_loss:\n","        best_test_loss = test_loss\n","        patience_counter = 1\n","    else:\n","        patience_counter += 1\n","\n","    if patience_counter > 3:\n","        break\n"]},{"cell_type":"markdown","metadata":{"id":"5ODXxagcAdiW"},"source":["### Question 14: the following cell shows some images and their approximation with the VAE. What do you think of the result? Test again this cell when LATENT_DIM > 2"]},{"cell_type":"markdown","metadata":{"id":"aKApJvexkECF"},"source":["#### Answer:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C80XNkQTf5bL","executionInfo":{"status":"aborted","timestamp":1706173109575,"user_tz":-60,"elapsed":3,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","plt.ion() # Turn the interactive mode on.\n","\n","import torchvision.utils\n","\n","model.eval()\n","\n","# Make sure that the image pixels are between 0 and 1\n","def to_img(x):\n","    x = x.clamp(0, 1)\n","    return x\n","\n","# To plot an image\n","def show_image(img):\n","    img = to_img(img)\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","# To visualize the images reconstructed by a given model\n","def visualise_output(images, model):\n","    with torch.no_grad():\n","        images = images.view(-1, 28 * 28)\n","        images = images.to(device)\n","        images, _, _ = model(images)\n","        images = images.cpu()\n","        images = to_img(images)\n","        images = images.view(-1, 1, 28, 28)\n","        np_imagegrid = torchvision.utils.make_grid(images, 10, 7).numpy()\n","        plt.imshow(np.transpose(np_imagegrid, (1, 2, 0)))\n","        plt.show()\n","\n","test_iterator_iter = iter(test_iterator)\n","images, labels = next(test_iterator_iter)\n","#print(images.size())\n","\n","# First visualise the original images\n","print('Original images')\n","show_image(torchvision.utils.make_grid(images,10,7))\n","plt.show()\n","\n","# Reconstruct and visualise the images using the vae\n","print('VAE reconstruction:')\n","visualise_output(images, model)"]},{"cell_type":"markdown","metadata":{"id":"sx2mMoKXf5bV"},"source":["#### Show 2D Latent Space"]},{"cell_type":"markdown","metadata":{"id":"i8rX_PoykECG"},"source":["### Question 15: the following cell shows some images when the latent space is sampled. It works only when when LATENT_DIM = 2. What do you think of the generated images?"]},{"cell_type":"markdown","metadata":{"id":"xm0kDVaokECG"},"source":["#### Answer:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VWBrf5R7f5bV","executionInfo":{"status":"aborted","timestamp":1706173109575,"user_tz":-60,"elapsed":14232,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# load a network that was trained with a 2d latent space\n","if LATENT_DIM != 2:\n","    raise Exception('Please change the parameters to two latent dimensions.')\n","\n","# set the evaluation mode\n","model.eval()\n","\n","with torch.no_grad():\n","\n","    # create a sample grid in 2d latent space\n","    latent_x = np.linspace(-1.5,1.5,20)\n","    latent_y = np.linspace(-1.5,1.5,20)\n","    latents = torch.FloatTensor(len(latent_y), len(latent_x), 2)\n","    for i, lx in enumerate(latent_x):\n","        for j, ly in enumerate(latent_y):\n","            latents[j, i, 0] = lx\n","            latents[j, i, 1] = ly\n","    latents = latents.view(-1, 2) # flatten grid into a batch\n","\n","    # reconstruct images from the latent vectors\n","    latents = latents.to(device)\n","    image_recon = model.dec(latents)\n","    image_recon = image_recon.cpu()\n","    image_recon = to_img(image_recon)\n","    image_recon = image_recon.view(-1, 1, 28, 28)\n","\n","    fig, ax = plt.subplots(figsize=(10, 10))\n","    show_image(torchvision.utils.make_grid(image_recon.data[:400],20,5))\n","    plt.xlabel(\"1st latent dimension\")\n","    plt.ylabel(\"2nd latent dimension\")\n","    plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}