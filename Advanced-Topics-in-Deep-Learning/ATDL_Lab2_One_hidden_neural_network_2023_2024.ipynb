{"cells":[{"cell_type":"markdown","metadata":{"id":"T2Pf-okiDOoi"},"source":["# Lab 2: One hidden neural network with finite-sample expressivity\n","\n","This lab studies a one hidden neural network with $N$ hidden neurons that can approximate any finite set with $N$ samples.\n","\n","Author: Lionel Fillatre"]},{"cell_type":"markdown","metadata":{"id":"UNdECWv6DOoj"},"source":["# Objective\n","\n","For weight vectors $w,b\\in \\mathbb{R}^N$ and $a\\in \\mathbb{R}^n$, we consider the function $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$,\n","$$\n","f(x)=\\sum_{j=1}^{N}w_j \\max\\{a^Tx-b_j,0\\}.\n","$$\n","\n","Let $S$ be any sample $S = \\{x_1,\\ldots,x_N\\}$ of size $N$ with $x_i \\in\\mathbb{R}^n$ and some target vectors $y_i \\in \\mathbb{R}^N$.\n","It is assumed that all the $x_i's$ are distinct.\n","\n","We want to find weights $a$, $b$, $w$ so that $y_i = f(x_i)$ for all $i \\in \\{1,\\ldots,N\\}$."]},{"cell_type":"markdown","metadata":{"id":"7VCkL5O-DOok"},"source":["### Question 1:\n","\n","Verify that $f(x)$ can be expressed by a depth $2$ network (one hidden layer only) with ReLU activations."]},{"cell_type":"markdown","metadata":{"id":"YO0eUCcSDOok"},"source":["Write your answer here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRVK7AuKDOok"},"outputs":[],"source":["import torch\n","import numpy as np\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izB-OobADOol","outputId":"ac3e5dd5-e898-4fe7-9932-09737f9a0985"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fa945343230>"]},"metadata":{},"execution_count":2}],"source":["seed = 79790\n","torch.manual_seed(seed) # set the seed of the random generator"]},{"cell_type":"markdown","metadata":{"id":"-zO5Tq7aDOol"},"source":["# Data generation"]},{"cell_type":"markdown","metadata":{"id":"7ReauekLDOol"},"source":["### Question 2:\n","\n","As a numerical example to test our mathematical results, we simulate some synthetic samples. Use ``torch.randn'' to generate the random samples $x_i$. Each $x_{i,j}$ must follow the distribution $\\mathcal{N}(0,\\frac{1}{n})$. You can generate $N=5$ random samples with $n=2$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GiW7UdyDOom"},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"AHgKP1n4DOom"},"source":["### Question 3:\n","\n","We also simulate the labels. For each $x_i$, generate the label $y_i$ as\n","\t\t$$\n","\t\ty_i=\\min\\left\\{10,\\max\\left\\{1,\\frac{1}{n}\\sum_{j=1}^{n}  \\left|\\sinh( n^2\\,x_{i,j}) \\right| \\right\\}\\right\\}.\n","\t\t$$"]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"2coczYtfDc0F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"id":"1UyGZx4XDOom"},"source":["# Neural network parameters"]},{"cell_type":"markdown","metadata":{"id":"dj3Tjk9EDOon"},"source":["### Question 4:\n","\n","Show that we can find $a\\in\\mathbb{R}^n$ such that, with $z_i = a^Tx_i$, we have $z_i\\neq z_j$ for all $1\\leq i\\neq j\\leq N$. In the rest of the exercise, we assume that $z_1  < z_2 < \\ldots < z_N$ (even if we swap the $x_i$'s and the $y_i$'s).\n","\n","Hint: a finite union of hyperplanes in $\\mathbb{R}^n$ can not cover $\\mathbb{R}^n$."]},{"cell_type":"markdown","metadata":{"id":"2U4FdlWUDOon"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"cfkHJ79gDOon"},"source":["### Question 5:\n","\n","Imagine a random mecanism to generate $a$. Generate $a$ in Python.\n","\n","Hint: a finite union of hyperplanes in $\\mathbb{R}^n$ can not cover $\\mathbb{R}^n$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9H5sI2T2DOon"},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"QaiBGN-5DOon"},"source":["### Question 6:\n","\n","Show that we can find $a$ and $b$ such that, with $z_i = a^Tx_i$, we have the interleaving property $b_1 < z_1 < b_2 < z_2 < \\ldots < b_N < z_N$."]},{"cell_type":"markdown","metadata":{"id":"pwgnnAZ_DOon"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"lEKWKuySDOon"},"source":["### Question 7:\n","\n","Compute the $z_i$'s in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4wlErGdDOon"},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"4eg2GKVBDOoo"},"source":["### Question 8:\n","\n","Compute the $b_i$'s in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJlkwYV5DOoo"},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"63GnQyzBDOoo"},"source":["### Question 9:\n","\n","Show that the $N \\times N$ matrix $A =\\left( a_{i,j} \\right)$ with  $a_{i,j}=\\max\\{z_i-b_j , 0\\}$ is lower triangular."]},{"cell_type":"markdown","metadata":{"id":"fF4jZUEMDOoo"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"-jQtYYwIDOoo"},"source":["### Question 10:\n","\n","Compute the matrix $A$ in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbcxaBLVDOoo"},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"PUfWkkVKDOoo"},"source":["### Question 11:\n","\n","Show that $A$ has full rank."]},{"cell_type":"markdown","metadata":{"id":"2Mh-LJx-DOoo"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"8VuEu_qaDOoo"},"source":["### Question 12:\n","\n","Compute the determinant of $A$ in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwrvtNqNDOoo"},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"66--PFFcDOop"},"source":["### Question 13:\n","\n","Consider the set of $N$ equations $y_i=f(x_i)$ for $i \\in \\{1,\\ldots,N\\}$. Show that $f(x_i) = A_i w$ where $A_i$ is the $i$-th row of $A$."]},{"cell_type":"markdown","metadata":{"id":"u87vFxVKDOop"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"_fSKwDDIDOop"},"source":["### Question 14:\n","\n","Show that we can find $w$ such that $y_i = f(x_i)$ for all $i \\in \\{1,\\ldots,N\\}$."]},{"cell_type":"markdown","metadata":{"id":"jJ2C17L6DOop"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"K5epPwy6DOop"},"source":["### Question 15:\n","\n","Compute the optimal $w$ in Python."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MK7PTFDEDOop"},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"-Vnkb_fADOop"},"source":["# Neural network implementation"]},{"cell_type":"markdown","metadata":{"id":"VJCL_-NiDOop"},"source":["### Question 16:\n","\n","Write a neural network class \"Net(nn.Module)\" which implements the depth 2 network with the parameters you have computed in the previous cells."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQnAhTj3DOop"},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"DQhUVfemDOop"},"source":["### Question 17:\n","\n","Generate a test set with the same size as the training set. Compare the training loss and the test loss."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sw1OJDOnDOop"},"outputs":[],"source":["# Write your code here."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}