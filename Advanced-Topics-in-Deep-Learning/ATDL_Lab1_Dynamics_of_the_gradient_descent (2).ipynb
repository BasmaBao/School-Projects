{"cells":[{"cell_type":"markdown","metadata":{"id":"qTIPSM_EakZl"},"source":["# Lab 1: Teacher-Student estimation problem\n","\n","We study the generalization error dynamics in a shallow linear neural network receiving $n$-dimensional inputs. We consider a standard student-teacher formulation.\n"]},{"cell_type":"markdown","metadata":{"id":"qYtln9X5akZo"},"source":["Import the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQGN3zLIakZp"},"outputs":[],"source":["import torch\n","import numpy as np\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLbu3oidakZq","executionInfo":{"status":"ok","timestamp":1670229338126,"user_tz":-60,"elapsed":461,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"1ddb5c29-875d-4986-8ec0-1a299a9dc392"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f3174add6d0>"]},"metadata":{},"execution_count":23}],"source":["seed = 79790\n","torch.manual_seed(seed) # set the seed of the random generator"]},{"cell_type":"markdown","metadata":{"id":"T2zuCWa2akZq"},"source":["##Teacher model\n","\n","The teacher implements a noisy linear mapping between $N$ inputs $x_i\\in\\mathbb{R}^n$:\n","\\begin{equation}\n","y_i=x_i^T\\beta+\\varepsilon_i=\\sum_{j=1}^{n}x_{i,j}\\beta_j+\\varepsilon_i,\\:i=1,\\ldots,N.\n","\\end{equation}\n","We assume that the inputs $x_{i,j}$ are drawn i.i.d. from a Gaussian with mean zero and variance $\\frac{1}{n}$ so that each example will have an expected norm of one: $\\mathbb{E}({\\left\\lVert x_i\\right\\rVert}^2_2)= 1$. \n","\n","In matrix form, we get\n","\\begin{equation}\\label{eq:teacher-mechanism}\n","y = S\\beta+\\varepsilon\n","\\end{equation}\n","where the $i$-th row of $S \\in \\mathbb{R}^{N\\times n}$ is $x_i^T$, $y=(y_1,\\ldots,y_N) \\in \\mathbb{R}^{N}$ and $\\varepsilon=(\\varepsilon_1,\\ldots,\\varepsilon_N) \\in \\mathbb{R}^{N}$. We assume that $N>n$ and that $S$ is a full column rank matrix.\n","\n","In the equation above, $\\varepsilon$ denotes noise in the teacher’s output. We will model both the noise $\\varepsilon_i$ and the teacher weights $\\beta_j$ as drawn i.i.d. from a random Gaussian distribution with zero mean and variance $\\sigma^2_{\\varepsilon}$ and $\\sigma^2_{\\beta}$ respectively. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"mp-8Z6Q6akZr"},"source":["### Question 1: Code the teacher data generation mechanism in Pytorch. Use the tensors of Pytorch to store the training data $S$ and $y$. You will take on $n=4$, $N=20$, $\\sigma_{\\beta}=0.7$, and $\\sigma_{\\varepsilon}=1.5$."]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"4PzY2BrBa1I7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1mwuk6u2akZs"},"source":["Teacher parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eb6CR10VakZt"},"outputs":[],"source":["N = 20 # number of samples for the training\n","n = 4 # Dimension of the input\n","sigma_beta = 0.7  # initialization of the teacher\n","sigma_epsilon = 1.5 # initialization of the noise\n"]},{"cell_type":"markdown","metadata":{"id":"QCqVDUftakZv"},"source":["##Student model\n","\n","The student network with weight vector $w \\in \\mathbb{R}^{n}$ is trained on examples $x_i$ generated by a teacher network:\n","\n","$$\n","\\hat{y}_i=x_i^\\top w.\n","$$"]},{"cell_type":"markdown","metadata":{"id":"H8qdR-STakZv"},"source":["**Training the student model**\n","\n","The student network is trained using the dataset $\\{y,S\\}$ to accurately predict outputs for novel inputs $x \\in \\mathbb{R}^n$ . \n","The student is a shallow linear network, such that the student’s prediction $\\hat{y}\\in\\mathbb{R}$ is simply $\\hat{y}=x^Tw$. \n","\n","To learn its parameters, the student network will attempt to minimize the mean squared error on the $N$ training samples using gradient descent. The training error is\n","\\begin{equation}\\label{eq:train-error}\n","E_r(w)=\\frac{1}{N}\\sum_{i=1}^{N}{( y_i -  \\hat{y}_i)}^2=\\frac{1}{N}\\sum_{i=1}^{N}{( y_i -  x_i^T w)}^2=\\frac{1}{N}{\\left\\lVert y -  Sw \\right\\rVert}^2_2.\n","\\end{equation}\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eTT-FIi_akZw"},"source":["### Question 2: Write $E_r(w)$ under the form \n","\\begin{equation}\n","E_r(w)=\\frac{1}{N}{\\left\\lVert y -  Sw \\right\\rVert}^2_2.\n","\\end{equation}"]},{"cell_type":"markdown","metadata":{"id":"3TehggrfakZw"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"_LQ772yZakZw"},"source":["### Question 3: Calculate the gradient of $E_r(w)$ with respect to $w$. Write the gradient in matrix form."]},{"cell_type":"markdown","metadata":{"id":"MXGg56W_akZw"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"5SlXyg-JakZw"},"source":["### Question 4: What is the minimum value of $E_r(w)$? This value is denoted $E_r^*$."]},{"cell_type":"markdown","metadata":{"id":"iHzjXFRCakZw"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"avEPloCiakZx"},"source":["### Question 5: Compute the optimal weights $w^*$ such that $E_r(w^*)=E_r^*$ and $E_r^*$."]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"5hctfB3da9ft"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"udWCOgpbakZx"},"source":["##Generalization error\n","\n","We will study the generalization error\n","\\begin{equation}\n","E_g(t)=E_g(w(t))=\\mathbb{E}_{X,Y}{\\left(Y-X^Tw(t)\\right)}^2=\\mathbb{E}_{X,\\varepsilon}{\\left(X^T\\beta+\\varepsilon-X^Tw(t)\\right)}^2,\n","\\end{equation}\n","where $w(t)$ is the student weight estimated at time $t$ during the gradient descent and $\\varepsilon$ is a random value following a Gaussian distribution with zero mean and variance $\\sigma^2_{\\varepsilon}$.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U4He77DVakZx"},"source":["### Question 6: What is the oracle error $E_\\infty=\\mathbb{E}_{X,Y}{\\left(Y-X^Tw(t)\\right)}^2$ when $w(t)=\\beta$ ?"]},{"cell_type":"markdown","metadata":{"id":"lj1LIepRakZx"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"aLuquB1wakZx"},"source":["### Question 7: Generate an evaluation dataset with 10 000 teacher samples. This dataset will be used to compute the evaluation error of the trained student network during the training."]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"DOtN7wHXbB28"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECPKvyhGakZy"},"source":["##Gradient descent\n","\n","We will use the full gradient descent algorithm to minimize $E_r(w)$:\n","\\begin{equation}\n","w_{k+1}=w_{k}-\\lambda \\nabla E_r(w_{k})\n","\\end{equation}\n","where $\\lambda>0$ is a small constant learning rate.\n","We assume that the starting weights $w{(0)}_i$ are drawn i.i.d. from a Gaussian with mean zero and variance $\\sigma^2_0$. \n"]},{"cell_type":"markdown","metadata":{"id":"YqL4vu6AakZy"},"source":["### Question 8: Implement a shallow neural network in Pytorch to learn $w$ by minimizing the error. The neural network will have only one fully connected layer with no bias. You will use the SGD optimizer from the library \"torch.optim\". You will take on $\\sigma_{0}=0.2$ and the learning rate should be close to $0.01$. The number of iterations will be close to 2 500. You must compute both the training error (on the training dataset) and the evaluation (on the evaluation dataset)."]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"DyqVRKPtbFBO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ndRcnmLCakZz"},"source":["### Question 9: Plot the training error $E_r(t)=E_r(w(t))$ as a function of the gradient descent iterates $t=1,2,\\ldots$. You can use the libraries ``matplotlib'' and ``numpy'' to plot the error. Plot on the same graph the constant oracle error $E_\\infty$ and also the optimal training error $E_r^*$."]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"2x5vGITLbIBs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Trajectory of the gradient descent\n","\n","As shown in the lecture, the gradient descent trajectory is approximated by the solution of \n","\\begin{equation}\n","\t\\tau\\, \\dot{w}(t) = S^Ty-S^TSw(t)\n","\\end{equation}\n","with $\\tau=\\frac{N}{2}$.\n","\n","By using an appropriate change of variables, we get $n$ uncoupled differential equations\n","$$\n","\\tau \\dot{z}_i(t)=(\\delta_i-z_i(t)) \\lambda_i+\\gamma_i \\sqrt{\\lambda_i}\n","$$\n","\n","Their solutions are\n","\n","$$\n","z_i(t)=\\delta_i+(z_i(0)-\\delta_i)e^{-\\frac{\\lambda_i}{\\tau}t}+\\frac{\\gamma_i}{\\sqrt{\\lambda_i}}(1-e^{-\\frac{\\lambda_i}{\\tau}t})\n","$$\n","\n","where $S^\\top S=V\\Lambda V^\\top$, $z=V^\\top w$, $\\delta=V^\\top \\beta$ and $\\gamma=\\Lambda^{-\\frac{1}{2}}V^\\top S^\\top\\varepsilon$. The diagonal elements of $\\Lambda$ are the eigenvalues $\\lambda_i$.\n","\n","All the notations are defined in the lecture."],"metadata":{"id":"d2aeZfrvctDv"}},{"cell_type":"markdown","metadata":{"id":"F6YKIwBeakZz"},"source":["### Question 10: Compute the $n$ functions $z_i(t)$ for $t=k \\lambda$ where $k=0,1,\\ldots,N$\n","\t"]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"EM-tBymMbLFa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"noCnbjEGakZ0"},"source":["### Question 11: Compute the coupled trajectories $w(t)=Vz(t)$."]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"Fs8qKx4rbMnR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAV0kHr8akZ0"},"source":["### Question 12: Plot the empirical learned weights together with the approximated analytic solution $w(t$ as a function of the gradient descent iterates $t=1,2,\\ldots$. Plot on the same graph the true coefficients $\\beta$, the optimal training weights $w^*$ and the initial weight $w(0)$."]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"bv3SnngYbOdc"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}