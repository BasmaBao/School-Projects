{"cells":[{"cell_type":"markdown","metadata":{"id":"T2Pf-okiDOoi"},"source":["# Lab 2: One hidden neural network with finite-sample expressivity\n","\n","This lab studies a one hidden neural network with $N$ hidden neurons that can approximate any finite set with $N$ samples.\n","\n","Author: Lionel Fillatre"]},{"cell_type":"markdown","metadata":{"id":"UNdECWv6DOoj"},"source":["# Objective\n","\n","For weight vectors $w,b\\in \\mathbb{R}^N$ and $a\\in \\mathbb{R}^n$, we consider the function $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$,\n","$$\n","f(x)=\\sum_{j=1}^{N}w_j \\max\\{a^Tx-b_j,0\\}.\n","$$\n","\n","Let $S$ be any sample $S = \\{x_1,\\ldots,x_N\\}$ of size $N$ with $x_i \\in\\mathbb{R}^n$ and some target vectors $y_i \\in \\mathbb{R}$.\n","It is assumed that all the $x_i's$ are distinct.\n","\n","We want to find weights $a$, $b$, $w$ so that $y_i = f(x_i)$ for all $i \\in \\{1,\\ldots,N\\}$."]},{"cell_type":"markdown","metadata":{"id":"7VCkL5O-DOok"},"source":["### Question 1:\n","\n","Verify that $f(x)$ can be expressed by a depth $2$ network (one hidden layer only) with ReLU activations."]},{"cell_type":"markdown","metadata":{"id":"YO0eUCcSDOok"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"0ay5E0bhDOok"},"source":["### Answer 1:\n","\n","The claim is straightforward."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"GRVK7AuKDOok","executionInfo":{"status":"ok","timestamp":1670859358530,"user_tz":-60,"elapsed":5041,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izB-OobADOol","executionInfo":{"status":"ok","timestamp":1670859358906,"user_tz":-60,"elapsed":389,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"5b7edec6-c11c-431f-ad7e-91a415f3ba93"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f14ea926170>"]},"metadata":{},"execution_count":2}],"source":["seed = 79790\n","torch.manual_seed(seed) # set the seed of the random generator"]},{"cell_type":"markdown","metadata":{"id":"-zO5Tq7aDOol"},"source":["# Data generation"]},{"cell_type":"markdown","metadata":{"id":"7ReauekLDOol"},"source":["### Question 2:\n","\n","As a numerical example to test our mathematical results, we simulate some synthetic samples. Use ``torch.randn'' to generate the random samples $x_i$. Each $x_{i,j}$ must follow the distribution $\\mathcal{N}(0,\\frac{1}{n})$. You can generate $N=5$ random samples with $n=2$."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2GiW7UdyDOom","executionInfo":{"status":"ok","timestamp":1670859358907,"user_tz":-60,"elapsed":9,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"WqDQmWFkDOom"},"source":["### Answer 2: \n","\n","Generate the samples"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE6B88TlDOom","executionInfo":{"status":"ok","timestamp":1670859358907,"user_tz":-60,"elapsed":9,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"598d31a8-5ae0-4359-e9b7-fb2ffd4fc042"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 2])\n","tensor(0.6308)\n"]}],"source":["N = 5 # number of samples for the training\n","n = 2\n","\n","X = 1/np.sqrt(n)*torch.randn(N, n)\n","print(X.shape)\n","\n","# compute the norm of the square rows\n","sumX2 = torch.sum(X**2, 1)\n","print(sumX2.mean())"]},{"cell_type":"markdown","metadata":{"id":"AHgKP1n4DOom"},"source":["### Question 3:\n","\n","We also simulate the labels. For each $x_i$, generate the label $y_i$ as\n","\t\t$$\n","\t\ty_i=\\min\\left\\{10,\\max\\left\\{1,\\frac{1}{n}\\sum_{j=1}^{n}  \\left|\\sinh( n^2\\,x_{i,j}) \\right| \\right\\}\\right\\}.\n","\t\t$$"]},{"cell_type":"code","source":["# Write your code here."],"metadata":{"id":"2coczYtfDc0F","executionInfo":{"status":"ok","timestamp":1670859358907,"user_tz":-60,"elapsed":6,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5KkbsAaYDOom"},"source":["### Answer 3: Generate the labels"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tHUtmACoDOom","executionInfo":{"status":"ok","timestamp":1670859358908,"user_tz":-60,"elapsed":7,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"9897ce4d-b7ff-44d2-cdce-f7a8658eae2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 2.1582],\n","        [ 8.6118],\n","        [10.0000],\n","        [ 2.9842],\n","        [ 1.6595]])\n","torch.Size([5, 1])\n"]}],"source":["def generate_target(X):\n","    S = torch.mean(torch.abs(torch.sinh(((n**2)*X))),1)\n","    Y = torch.clamp(S, min=1, max=10).view(-1,1)\n","    return Y\n","\n","Y = generate_target(X)\n","print(Y)\n","print(Y.shape)"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"1UyGZx4XDOom"},"source":["# Neural network parameters "]},{"cell_type":"markdown","metadata":{"id":"dj3Tjk9EDOon"},"source":["### Question 4:\n","\n","Show that we can find $a\\in\\mathbb{R}^n$ such that, with $z_i = a^Tx_i$, we have $z_i\\neq z_j$ for all $1\\leq i\\neq j\\leq N$. In the rest of the exercise, we assume that $z_1  < z_2 < \\ldots < z_N$ (even if we swap the $x_i$'s and the $y_i$'s).\n","\t\t\t\n","Hint: a finite union of hyperplanes in $\\mathbb{R}^n$ can not cover $\\mathbb{R}^n$."]},{"cell_type":"markdown","metadata":{"id":"2U4FdlWUDOon"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"1sOy1JJ-DOon"},"source":["### Answer 4:\n","\n","It is clear that $z_i\\neq z_j$ if and only if $a^T(x_i-x_j)\\neq 0$. Hence, $a$ should not belong to the hyperplane $H_{i,j}$ whose normal vector is $x_i-x_j\\neq 0$ (because the $n$ vectors $x_i's$ are distinct).\n","\n","Hence, we must find a vector $a$ which does not belong to $\\cup_{i\\neq j}H_{i,j}$.\n","\n","Since a finite union of hyperplanes can not cover $\\mathbb{R}^n$, we can find a vector $a$. "]},{"cell_type":"markdown","metadata":{"id":"cfkHJ79gDOon"},"source":["### Question 5:\n","\n","Imagine a random mecanism to generate $a$. Generate $a$ in Python."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"9H5sI2T2DOon","executionInfo":{"status":"ok","timestamp":1670859358908,"user_tz":-60,"elapsed":5,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"7hTbSFdpDOon"},"source":["### Answer 5:\n","\n","Generate the vector as a random Gaussian vector because its probability to belong to $\\cup_{i\\neq j}H_{i,j}$ is tiny."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6s9hQn4UDOon","executionInfo":{"status":"ok","timestamp":1670859359416,"user_tz":-60,"elapsed":512,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"0b56bf32-926a-45dd-c996-2080b1b9e7ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.1177],\n","        [-1.3662]])\n","torch.Size([2, 1])\n"]}],"source":["a = torch.randn(n,1)\n","print(a)\n","print(a.shape)"]},{"cell_type":"markdown","metadata":{"id":"QaiBGN-5DOon"},"source":["### Question 6:\n","\n","Show that we can find $a$ and $b$ such that, with $z_i = a^Tx_i$, we have the interleaving property $b_1 < z_1 < b_2 < z_2 < \\ldots < b_N < z_N$."]},{"cell_type":"markdown","metadata":{"id":"pwgnnAZ_DOon"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"gB6s16VCDOon"},"source":["### Answer 6:\n","\n","We can find $a\\in\\mathbb{R}^d$ such that $z_1  < z_2 < \\ldots < z_n$. It is then easy to find an interleaving sequence of $b_j$'s. For example, $b_1=z_1-1$ and $b_i=(z_{i-1}+z_i)/2$ for $2\\leq i \\leq N$."]},{"cell_type":"markdown","metadata":{"id":"lEKWKuySDOon"},"source":["### Question 7:\n","\n","Compute the $z_i$'s in Python."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"I4wlErGdDOon","executionInfo":{"status":"ok","timestamp":1670859359416,"user_tz":-60,"elapsed":30,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"xSunZNcODOon"},"source":["### Answer 7:\n","\n","Generate the values $z_i$ and sort them."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7yRI3CYDOon","executionInfo":{"status":"ok","timestamp":1670859359416,"user_tz":-60,"elapsed":29,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"735a0c18-4b4d-492a-c996-577d8ee7507d"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5])\n","tensor([-0.5108,  0.2979,  0.6959,  0.8192,  1.2136])\n","torch.Size([5])\n"]}],"source":["Z=X.mm(a)\n","Z = torch.squeeze(Z, 1)\n","print(Z.shape)\n","\n","Asort = torch.argsort(Z, dim=0)\n","Zsort = Z[Asort]\n","print(Zsort)\n","print(Zsort.shape)"]},{"cell_type":"markdown","metadata":{"id":"4eg2GKVBDOoo"},"source":["### Question 8:\n","\n","Compute the $b_i$'s in Python."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"UJlkwYV5DOoo","executionInfo":{"status":"ok","timestamp":1670859359417,"user_tz":-60,"elapsed":26,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"YEQPb7duDOoo"},"source":["### Answer 8:\n","\n","We compute the $b_i$'s."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qaatlfTsDOoo","executionInfo":{"status":"ok","timestamp":1670859359418,"user_tz":-60,"elapsed":26,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"752cc79e-dd54-45d6-c87a-de940572e720"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4])\n","torch.Size([5])\n","tensor([-1.5108, -0.1065,  0.4969,  0.7575,  1.0164])\n"]}],"source":["mid = 0.5*(Zsort[1:]+Zsort[:-1])\n","print(mid.shape)\n","b0 = Zsort[0] - 1\n","b0 = torch.unsqueeze(b0, dim=0)\n","b = torch.cat((b0,mid),0)\n","print(b.shape)\n","print(b)"]},{"cell_type":"markdown","metadata":{"id":"63GnQyzBDOoo"},"source":["### Question 9:\n","\n","Show that the $N \\times N$ matrix $A =\\left( a_{i,j} \\right)$ with  $a_{i,j}=\\max\\{z_i-b_j , 0\\}$ is lower triangular."]},{"cell_type":"markdown","metadata":{"id":"fF4jZUEMDOoo"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"azcMcOjXDOoo"},"source":["### Answer 9:\n","\n","By its definition, the matrix $A$ is lower triangular, that is, all entries with $i < j$ vanish. "]},{"cell_type":"markdown","metadata":{"id":"-jQtYYwIDOoo"},"source":["### Question 10:\n","\n","Compute the matrix $A$ in Python."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"cbcxaBLVDOoo","executionInfo":{"status":"ok","timestamp":1670859359418,"user_tz":-60,"elapsed":10,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"lY5GC_7zDOoo"},"source":["### Answer 10:\n","\n","Generate the matrix $A$"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4iSgI4eDOoo","executionInfo":{"status":"ok","timestamp":1670859359418,"user_tz":-60,"elapsed":9,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"f613beb5-24ce-48e5-de94-100d086d0ce1"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 5])\n","torch.Size([5, 5])\n","tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [1.8087, 0.4044, 0.0000, 0.0000, 0.0000],\n","        [2.2067, 0.8024, 0.1990, 0.0000, 0.0000],\n","        [2.3300, 0.9257, 0.3223, 0.0617, 0.0000],\n","        [2.7245, 1.3201, 0.7167, 0.4561, 0.1972]])\n"]}],"source":["Zr = Zsort.view(-1,1).repeat(1,N)\n","br = b.view(1,-1).repeat(N,1)\n","print(Zr.shape)\n","print(br.shape)\n","Ar = Zr-br\n","A = torch.tril(Ar, diagonal=0)\n","print(A)"]},{"cell_type":"markdown","metadata":{"id":"PUfWkkVKDOoo"},"source":["### Question 11:\n","\n","Show that $A$ has full rank."]},{"cell_type":"markdown","metadata":{"id":"2Mh-LJx-DOoo"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"LskPYP5KDOoo"},"source":["### Answer 11:\n","\n","A basic linear algebra fact states that a lower-triangular matrix has full rank (i.e., is invertible) if and only if all of the entries on the diagonal are nonzero. \n","\n","Since, $x_i > b_i$, we have that $\\max\\{x_i-b_i , 0\\}>0$. Hence, A is invertible."]},{"cell_type":"markdown","metadata":{"id":"8VuEu_qaDOoo"},"source":["### Question 12:\n","\n","Compute the determinant of $A$ in Python."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"jwrvtNqNDOoo","executionInfo":{"status":"ok","timestamp":1670859359419,"user_tz":-60,"elapsed":8,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"2cnRbbEwDOoo"},"source":["### Answer 12:\n","\n","Compute the determinant to check the invertibility of the matrix $A$."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nWd7b_TtDOoo","executionInfo":{"status":"ok","timestamp":1670859359754,"user_tz":-60,"elapsed":342,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"5801bac5-4a5d-44d5-b379-473e1a8fae4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.0010)\n"]}],"source":["detA = torch.prod(torch.diagonal(A, 0))\n","print(detA)"]},{"cell_type":"markdown","metadata":{"id":"66--PFFcDOop"},"source":["### Question 13:\n","\n","Consider the set of $N$ equations $y_i=f(x_i)$ for $i \\in \\{1,\\ldots,N\\}$. Show that $f(x_i) = A_i w$ where $A_i$ is the $i$-th row of $A$."]},{"cell_type":"markdown","metadata":{"id":"u87vFxVKDOop"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"gIVu-omFDOop"},"source":["### Answer 13:\n","\n","The claim is straightforward since $a^Tx_i=z_i$."]},{"cell_type":"markdown","metadata":{"id":"_fSKwDDIDOop"},"source":["### Question 14:\n","\n","Show that we can find $w$ such that $y_i = f(x_i)$ for all $i \\in \\{1,\\ldots,N\\}$."]},{"cell_type":"markdown","metadata":{"id":"jJ2C17L6DOop"},"source":["Write your answer here."]},{"cell_type":"markdown","metadata":{"id":"AN-OdcqqDOop"},"source":["### Answer 14:\n","\n","We chose $a$ and $b$ so that $A$ has full rank. We can now solve the linear system $y = Aw$ to find suitable weights $w$. "]},{"cell_type":"markdown","metadata":{"id":"K5epPwy6DOop"},"source":["### Question 15:\n","\n","Compute the optimal $w$ in Python."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"MK7PTFDEDOop","executionInfo":{"status":"ok","timestamp":1670859359754,"user_tz":-60,"elapsed":10,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"sklIrIYJDOop"},"source":["### Answer 15:\n","\n","Compute the optimal weights of the one-hidden neural network."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-YDxlMsDOop","executionInfo":{"status":"ok","timestamp":1670859359755,"user_tz":-60,"elapsed":10,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"73689c8f-d123-4597-cf7c-1dd2f3ca9a49"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[   1.6595],\n","        [  17.3070],\n","        [ -77.3399],\n","        [ 130.1448],\n","        [-115.0084]])\n"]}],"source":["Ysort = Y[Asort]\n","Xsort = X[Asort,:]\n","wopt = torch.linalg.solve(A, Ysort)\n","print(wopt)"]},{"cell_type":"markdown","metadata":{"id":"-Vnkb_fADOop"},"source":["# Neural network implementation"]},{"cell_type":"markdown","metadata":{"id":"VJCL_-NiDOop"},"source":["### Question 16:\n","\n","Write a neural network class \"Net(nn.Module)\" which implements the depth 2 network with the parameters you have computed in the previous cells."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"bQnAhTj3DOop","executionInfo":{"status":"ok","timestamp":1670859359756,"user_tz":-60,"elapsed":9,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"mZUHSWapDOop"},"source":["### Answer 16:\n","\n","Define a one hidden neural network"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Ge60iBJIDOop","executionInfo":{"status":"ok","timestamp":1670859359756,"user_tz":-60,"elapsed":9,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class OneHiddenNN(torch.nn.Module):\n","    def __init__(self, n, h):\n","        super().__init__()\n","        self.hidden = torch.nn.Linear(n, h)\n","        self.output = torch.nn.Linear(h, 1)\n","\n","    def oracle_init(self, wo, wh, bh):\n","        # Initialization of the neural network\n","        self.output.weight.data = torch.clone(wo.view(1,-1)) \n","        self.output.bias.data = torch.tensor([0.0])\n","        self.hidden.weight.data = torch.clone(wh.view(1,-1).repeat(N,1))\n","        self.hidden.bias.data = -torch.clone(bh)\n","    \n","    def forward(self, x):\n","        x = self.hidden(x)\n","        x = torch.relu(x)\n","        x = self.output(x)\n","        return x\n","    \n","# Neural network instanciation\n","model_hand = OneHiddenNN(n, N)\n","loss_function = torch.nn.MSELoss()\n","\n","# Initialisation with some optimal parameters\n","model_hand.oracle_init(wopt,a,b)"]},{"cell_type":"markdown","metadata":{"id":"DQhUVfemDOop"},"source":["### Question 17:\n","\n","Generate a test set with the same size as the training set. Compare the training loss and the test loss."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"sw1OJDOnDOop","executionInfo":{"status":"ok","timestamp":1670859359756,"user_tz":-60,"elapsed":9,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}}},"outputs":[],"source":["# Write your code here."]},{"cell_type":"markdown","metadata":{"id":"CGz84rMbDOop"},"source":["### Answer 17:\n","\n","Let us compare the losses on a test set."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXYsh2-zDOop","executionInfo":{"status":"ok","timestamp":1670859359757,"user_tz":-60,"elapsed":10,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"95f85f62-e1c9-4746-bc9e-5b1f7d7db3a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(5.5707e-13, grad_fn=<MseLossBackward0>)\n","tensor(88.1685, grad_fn=<MseLossBackward0>)\n"]}],"source":["# Generation of test samples\n","Xtest = 1/np.sqrt(n)*torch.randn(N, n)\n","Ytest = generate_target(Xtest)\n","\n","# Train set\n","Yhat = model_hand(X)\n","loss = loss_function(Yhat, Y)\n","print(loss)\n","\n","# Test set\n","Yhat = model_hand(Xtest)\n","loss = loss_function(Yhat, Ytest)\n","print(loss)\n"]},{"cell_type":"markdown","metadata":{"id":"vGzb87wBDOoq"},"source":["# Bonus:\n","\n","We train a neural network from a random initialization and compare it to the previous neural network."]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_tfGDra2DOoq","executionInfo":{"status":"ok","timestamp":1670859362171,"user_tz":-60,"elapsed":2422,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"11624bac-fb85-439a-cf59-4104ef334c9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 Training Loss:  35.93419647216797\n","Epoch: 50 Training Loss:  4.126924991607666\n","Epoch: 100 Training Loss:  1.8737423419952393\n","Epoch: 150 Training Loss:  1.5527673959732056\n","Epoch: 200 Training Loss:  1.37189519405365\n","Epoch: 250 Training Loss:  1.2210630178451538\n","Epoch: 300 Training Loss:  1.0877878665924072\n","Epoch: 350 Training Loss:  0.9559024572372437\n","Epoch: 400 Training Loss:  0.8256281614303589\n","Epoch: 450 Training Loss:  0.6995629072189331\n","Epoch: 500 Training Loss:  0.5807396769523621\n","Epoch: 550 Training Loss:  0.4719986021518707\n","Epoch: 600 Training Loss:  0.37553268671035767\n","Epoch: 650 Training Loss:  0.2926039695739746\n","Epoch: 700 Training Loss:  0.2234695851802826\n","Epoch: 750 Training Loss:  0.16749699413776398\n","Epoch: 800 Training Loss:  0.12339556217193604\n","Epoch: 850 Training Loss:  0.09084846079349518\n","Epoch: 900 Training Loss:  0.06931430101394653\n","Epoch: 950 Training Loss:  0.054874517023563385\n"]}],"source":["model = OneHiddenNN(n, N)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","\n","train_loss, test_loss = [], []\n","nbepoch = 1000 # Number of epochs\n","\n","for epoch in range(nbepoch): ## run the model for 10 epochs\n","\n","    optimizer.zero_grad()\n","    ## 1. forward propagation\n","    output = model(X)\n","    \n","    # Result on the test set\n","    outputTest = model(Xtest)\n","    lossTest = loss_function(outputTest, Ytest)\n","    test_loss.append(lossTest.item())\n","        \n","    ## 2. loss calculation\n","    loss = loss_function(output, Y)\n","        \n","    ## 3. backward propagation\n","    loss.backward()\n","        \n","    ## 4. weight optimization\n","    optimizer.step()\n","        \n","    train_loss.append(loss.item())\n","    \n","    if (epoch % 50) == 0:\n","        print (\"Epoch:\", epoch, \"Training Loss: \", (loss.item()))"]},{"cell_type":"markdown","metadata":{"id":"3A1nr_nvDOoq"},"source":["Print the loss with respect to the epoch"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"wvDKYjVqDOoq","executionInfo":{"status":"ok","timestamp":1670859362613,"user_tz":-60,"elapsed":448,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"27bed38c-85c2-4ca6-ec6e-f3ab54fa31d2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["T = range(nbepoch)\n","figure = plt.figure()\n","b1 = plt.plot(T, train_loss, 'b-', label='Train loss')\n","b2 = plt.plot(T, test_loss, 'r-', label='Test loss')\n","plt.xlabel('Epoch')\n","plt.legend(loc='upper center', shadow=True, fontsize='x-large')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"MYgH4ssaDOoq"},"source":["Print the parameters of the learned neural network"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUAr2FNvDOoq","executionInfo":{"status":"ok","timestamp":1670859362613,"user_tz":-60,"elapsed":9,"user":{"displayName":"Lionel Fillatre","userId":"14463393848879581998"}},"outputId":"47308c2d-2998-4480-98d2-332f9763b125"},"outputs":[{"output_type":"stream","name":"stdout","text":["hidden.weight tensor([[ 0.3484,  0.3147],\n","        [ 0.8679, -0.1029],\n","        [ 1.5717, -1.0192],\n","        [ 0.5172, -0.1034],\n","        [ 2.2336, -2.8602]])\n","hidden.bias tensor([-0.6407,  0.2703,  0.2970,  0.4063, -2.1024])\n","output.weight tensor([[-0.0689,  0.8772,  1.7967,  0.4139,  4.1006]])\n","output.bias tensor([0.5293])\n"]}],"source":["for name, param in model.named_parameters():\n","    if param.requires_grad:\n","        print(name, param.data)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[],"collapsed_sections":["1sOy1JJ-DOon","gB6s16VCDOon","azcMcOjXDOoo","LskPYP5KDOoo","gIVu-omFDOop","AN-OdcqqDOop"],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}