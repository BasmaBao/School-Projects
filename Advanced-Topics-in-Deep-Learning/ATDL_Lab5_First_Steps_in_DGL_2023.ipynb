{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfX28EAoCVke"
   },
   "source": [
    "# A First Neural Network on Graph\n",
    "=========================\n",
    "\n",
    "This lab is based on https://docs.dgl.ai/tutorials/basics/1_first.html\n",
    "\n",
    "DGL is a Python package dedicated to deep learning on graphs, built atop\n",
    "existing tensor DL frameworks (e.g. Pytorch, MXNet) and simplifying the\n",
    "implementation of graph-based neural networks.\n",
    "\n",
    "The goal of this tutorial:\n",
    "\n",
    "- Understand how DGL enables computation on graph from a high level.\n",
    "- Train a simple graph neural network in DGL to classify nodes in a graph.\n",
    "\n",
    "It is composed of 6 steps:\n",
    "- Step 1: Creating a graph in DGL\n",
    "- Step 2: Assign features to nodes or edges\n",
    "- Step 3: Define a Graph Convolutional Network (GCN)\n",
    "- Step 4: Data preparation and initialization\n",
    "- Step 5: Train then visualize\n",
    "- Step 6: Create your own GCN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7209,
     "status": "ok",
     "timestamp": 1673710108049,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "J0IPcKqxCVki",
    "outputId": "d9024914-432b-4ac1-cea2-39f4c1df92ac"
   },
   "outputs": [],
   "source": [
    "# You need to install the DGL library\n",
    "# With Anaconda, just use the Anaconda Navigator or conda install -c dglteam dgl\n",
    "# With Google Colab, run the following command line\n",
    "!pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710108049,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "76ud_eHhCVkj"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40UjZRH4CVkj"
   },
   "source": [
    "## Tutorial problem description\n",
    "--------------------------------------------------\n",
    "\n",
    "The tutorial is based on the \"Zachary's karate club\" problem. The karate club\n",
    "is a social network that includes 34 members and documents pairwise links\n",
    "between members who interact outside the club.  The club later divides into\n",
    "two communities led by the instructor (node 0) and the club president (node\n",
    "33). The network is visualized as follows with the color indicating the\n",
    "community:\n",
    "\n",
    "![](https://data.dgl.ai/tutorial/img/karate-club.png)\n",
    "\n",
    "\n",
    "The task is to predict which side (0 or 33) each member tends to join given\n",
    "the social network itself.\n",
    "\n",
    "A more detailled description is available on https://en.wikipedia.org/wiki/Zachary%27s_karate_club\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILtobAO7CVkk"
   },
   "source": [
    "## Step 1: Creating a graph in DGL\n",
    "--------------------------------------------\n",
    "Create the graph for Zachary's karate club as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4VzEAgLCVkk"
   },
   "source": [
    "### Question 1: what is \"dgl.graph()\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeWykmVSFcYU"
   },
   "source": [
    "#### Answer:\n",
    "DGL represents each node by a unique integer, called its node ID, and each edge by a pair of integers corresponding to the IDs of its end nodes. DGL assigns to each edge a unique integer, called its edge ID, based on the order in which it was added to the graph. The numbering of node and edge IDs starts from 0. In DGL, all the edges are directed, and an edge (ð‘¢,ð‘£) indicates that the direction goes from node ð‘¢ to node ð‘£.\n",
    "\n",
    "There are different ways to add nodes and edges. Here, we define the edges and the list of edges is the input of dgl.graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kib02P_qCVkk"
   },
   "source": [
    "### Question 2: how DGL is modelling undirected graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jy60nq7pERPA"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "The function considers all the couples (src, dst) and (dst, src). It follows that two arrows (directed edge) are assigned to each couple of nodes. Hence, an undirected edge is modeled as a couple of directed edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710108050,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "02iEYLlTCVkk",
    "outputId": "73ab9941-0209-47fc-dc1e-280747bc5144"
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "\n",
    "print(dgl.__version__)\n",
    "\n",
    "Nnodes = 34\n",
    "\n",
    "def build_karate_club_graph():\n",
    "    # All 78 edges are stored in two numpy arrays. One for source endpoints\n",
    "    # while the other for destination endpoints.\n",
    "    src = np.array([1, 2, 2, 3, 3, 3, 4, 5, 6, 6, 6, 7, 7, 7, 7, 8, 8, 9, 10, 10,\n",
    "        10, 11, 12, 12, 13, 13, 13, 13, 16, 16, 17, 17, 19, 19, 21, 21,\n",
    "        25, 25, 27, 27, 27, 28, 29, 29, 30, 30, 31, 31, 31, 31, 32, 32,\n",
    "        32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33,\n",
    "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33])\n",
    "    dst = np.array([0, 0, 1, 0, 1, 2, 0, 0, 0, 4, 5, 0, 1, 2, 3, 0, 2, 2, 0, 4,\n",
    "        5, 0, 0, 3, 0, 1, 2, 3, 5, 6, 0, 1, 0, 1, 0, 1, 23, 24, 2, 23,\n",
    "        24, 2, 23, 26, 1, 8, 0, 24, 25, 28, 2, 8, 14, 15, 18, 20, 22, 23,\n",
    "        29, 30, 31, 8, 9, 13, 14, 15, 18, 19, 20, 22, 23, 26, 27, 28, 29, 30,\n",
    "        31, 32])\n",
    "    # Edges are directional in DGL; Make them bi-directional.\n",
    "    u = np.concatenate([src, dst])\n",
    "    v = np.concatenate([dst, src])\n",
    "    # Construct a DGL graph\n",
    "    return dgl.graph((u, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Goj5-kURCVkl"
   },
   "source": [
    "Print out the number of nodes and edges in our newly constructed graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1673710108394,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "UIP_Dr6NCVkm",
    "outputId": "9fc439e4-e4a4-4949-ef10-6b8a5ee22f49"
   },
   "outputs": [],
   "source": [
    "G = build_karate_club_graph()\n",
    "print('We have %d nodes.' % G.number_of_nodes())\n",
    "print('We have %d edges.' % G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiFylmzYCVkm"
   },
   "source": [
    "Visualize the graph by converting it to a networkx graph.\n",
    "The library networkx is described on https://networkx.github.io/documentation/stable/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1673710109118,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "7dDZpBKrCVkm",
    "outputId": "9690c465-2944-4d35-8d10-7f05f97de93d"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Since the actual graph is undirected, we convert it for visualization purpose.\n",
    "nx_G = G.to_networkx().to_undirected()\n",
    "# Kamada-Kawaii layout usually looks pretty for arbitrary graphs\n",
    "pos = nx.kamada_kawai_layout(nx_G)\n",
    "nx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOn9NFxkCVkn"
   },
   "source": [
    "### Question 3: print the adjency matrix of the graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710109118,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "YN1QAe_4CVkn",
    "outputId": "064ce395-559a-4d87-f9ad-1999f28f4bdd"
   },
   "outputs": [],
   "source": [
    "#Fill in this cell\n",
    "print(G.adjacency_matrix()) # this is a sparse matrix: the indices correspond to matrix indices (location of non-zero coefficients)\n",
    "A = G.adjacency_matrix().to_dense() # A is the adjency matrix as a dense tensor. It is a 34x34 tensor of 0 or 1 values.\n",
    "print(A.shape)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4Twa5MOcBIT"
   },
   "source": [
    "### Question 4: create a DGL graph g with 6 nodes and the directed edges 0-1, 1->3, 2->4, 3->5\n",
    "\n",
    "Warning: The graph g is only used in this question. The rest of the lab concerns the graph G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1673710109361,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "mKPqth6OcBIT",
    "outputId": "257406e2-2b4c-48a1-82e0-fd0600fb9202"
   },
   "outputs": [],
   "source": [
    "# Fill in the cell\n",
    "g = dgl.graph([])\n",
    "g.add_nodes(6)  # 6 isolated nodes are added\n",
    "g.add_edges(0, 1)\n",
    "g.add_edges([1, 2, 3], [3, 4, 5])  # three edges: 1->3, 2->4, 3->5\n",
    "print(g.adjacency_matrix())\n",
    "A = g.adjacency_matrix().to_dense() # A is the adjency matrix as a dense tensor. It is a 34x34 tensor of 0 or 1 values.\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAWOAjHNCVkn"
   },
   "source": [
    "## Step 2: Assign features to nodes or edges\n",
    "--------------------------------------------\n",
    "Graph neural networks associate features with nodes and edges for training.\n",
    "For our classification example, we assign each node an input feature as a one-hot vector:\n",
    "node $v_i$'s feature vector is $[0,\\ldots,1,\\dots,0]$,\n",
    "where the $i^{th}$ position is one.\n",
    "\n",
    "In DGL, you can add features for all nodes at once, using a feature tensor that\n",
    "batches node features along the first dimension. The code below adds the one-hot\n",
    "feature for all nodes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sz9HLj1zCVkn"
   },
   "source": [
    "### Question 5: is the name \"feature\" crucial in the following cell? Can we replace it by an other name?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFkeb3WZNWT-"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "The name does not matter. Yes, we can use an other name. Of coure, when a name has been used, we must use it again to retrieve its value. \n",
    "\n",
    "\"ndata\" for node data.\n",
    "\n",
    "You can also add data to the edges with \"G.edata[...]\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1673710109361,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "FiXDihpTCVkn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "G.ndata['feature'] = torch.eye(Nnodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_BhXqFMCVko"
   },
   "source": [
    "### Question 6: create a new feature named \"featureRandom\" which associates a random normal vector of size 6 to each node. The vector must be generated with Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1673710109361,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "cmz0j6XuCVko"
   },
   "outputs": [],
   "source": [
    "# Fill in the cell\n",
    "G.ndata['featureRandom'] = torch.randn(34, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-rchrGxCVko"
   },
   "source": [
    "Print out the node features to verify:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1673710109361,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "UQRvzdkiCVko",
    "outputId": "051bb789-ed94-4b1a-f6b3-06e298416ce0"
   },
   "outputs": [],
   "source": [
    "# print out node 2's input feature\n",
    "print(G.nodes[2].data['featureRandom'])\n",
    "\n",
    "# print out node 10 and 11's input features\n",
    "print(G.nodes[[10, 11]].data['featureRandom'])\n",
    "\n",
    "# After assignments, each node or edge field will be associated with a scheme containing the shape and data type \n",
    "# (dtype) of its field value.\n",
    "print(G.node_attr_schemes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5x-xBMcUcBIU"
   },
   "source": [
    "### Question 7: Compute a node feature 'deg' that contains the out degree (number of outgoing edges) of the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1673710109361,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "-3U0Nu1EcBIU",
    "outputId": "897d1f20-f27c-4039-b039-9de436b9d2f2"
   },
   "outputs": [],
   "source": [
    "# Fill in the cell\n",
    "print(G.nodes())\n",
    "G.ndata['deg'] = G.out_degrees(G.nodes()).float()\n",
    "print(G.nodes[:].data['deg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X4w73XDcBIV"
   },
   "source": [
    "### Question 8: remove all the node features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1673710109361,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "qHB9yTsDcBIV",
    "outputId": "4dbc12f6-91ed-484b-feb8-242bfcced71c"
   },
   "outputs": [],
   "source": [
    "# Fill in the cell\n",
    "\n",
    "# You can also remove node or edge states from the graph. \n",
    "# This is particularly useful to save memory during inference.\n",
    "G.ndata.pop('feature')\n",
    "G.ndata.pop('featureRandom')\n",
    "G.ndata.pop('deg')\n",
    "print(G.node_attr_schemes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JJ5_j_qCVko"
   },
   "source": [
    "\n",
    "\n",
    "## Step 3: Define a Graph Convolutional Network (GCN)\n",
    "--------------------------------------------------\n",
    "To perform node classification, use the Graph Convolutional Network\n",
    "(GCN) developed by [Kipf and Welling](https://arxiv.org/abs/1609.02907) \n",
    "\n",
    "Here is the simplest definition of a GCN framework. We recommend that you \n",
    "read the original paper for more details.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MZFA6x1CVkq"
   },
   "source": [
    "### Question 9: give a mathematical description of the folllowing model GCN. What is the output of the neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfPKAZgscBIV"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "- At layer $l$, each node $v_i^l$ carries a feature vector $h_i^l$.\n",
    "- Each layer of the GCN tries to aggregate the features from $u_i^{l}$ where\n",
    "  $u_i$'s are neighborhood nodes to $v$ into the next layer representation at\n",
    "  $v_i^{l+1}$. This is followed by an affine transformation with some\n",
    "  non-linearity.\n",
    "\n",
    "The above definition of GCN fits into a **message-passing** paradigm: Each\n",
    "node will update its own feature with information sent from neighboring\n",
    "nodes. A graphical demonstration is displayed below.\n",
    "\n",
    "![mailbox](https://data.dgl.ai/tutorial/1_first/mailbox.png)\n",
    "\n",
    "The GraphConv module implements one Graph Convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710109361,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "7qcU-P_0CVkq"
   },
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a 2-layer GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.conv1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOiXpa1qCVkr"
   },
   "source": [
    "## Step 4: Data preparation and initialization\n",
    "-------------------------------------------\n",
    "\n",
    "We use one-hot vectors to initialize the node features. Since this is a\n",
    "semi-supervised setting, only the instructor (node 0) and the club president\n",
    "(node 33) are assigned labels. The implementation is available as follow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U79ByYW2S7z8"
   },
   "source": [
    "### Question 10: what is the role of the Embedding in the following?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoFknstDTCsD"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "It is a classical input embedding that linearly transforms some categorical inputs into numerical vectors. The categorical features are first encoded as one-hot vectors and then each one-hot vector is linearly transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1673710109362,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "P6qHysh_CVkr"
   },
   "outputs": [],
   "source": [
    "embed_dim = 3\n",
    "embed = nn.Embedding(Nnodes, embed_dim)  # 34 nodes with embedding dim equal to 3\n",
    "inputs = embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1673710109362,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "Cd43XaoYcBIV"
   },
   "outputs": [],
   "source": [
    "labeled_nodes = torch.tensor([0, 33])  # only the instructor and the president nodes are labeled\n",
    "labels = torch.tensor([0, 1])  # their labels are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1673710109362,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "vFo5-FJTcBIV"
   },
   "outputs": [],
   "source": [
    "# The first layer transforms input features of size of 'embed_dim' to a hidden size of 'hidden_dim'.\n",
    "# The second layer transforms the hidden layer and produces output features of\n",
    "# size 2, corresponding to the two groups of the karate club.\n",
    "hidden_dim = 10\n",
    "net = GCN(embed_dim, hidden_dim, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVaQ14TgCVkr"
   },
   "source": [
    "## Step 5: Train then visualize\n",
    "----------------------------\n",
    "The training loop is exactly the same as other PyTorch models.\n",
    "We (1) create an optimizer, (2) feed the inputs to the model,\n",
    "(3) calculate the loss and (4) use autograd to optimize the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrmymgzyCVkr"
   },
   "source": [
    "### Question 11: what is the optimization algorithm used for training the neural network? Why are we using \"itertools\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wO4CGVrlVRGQ"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "We use the Adam algorithm.\n",
    "\n",
    "It must update both the neural network parameters and the embedding layer parameters. \n",
    "\n",
    "\"itertools.chain\" chains (concatenates) two iterable objects. chain yields the elements of the first iterator until it gets exhausted, and then it yields the elements of the second one. In your code chain puts together the parameters of the two generators so they will be optimized simultaneously. Used for treating consecutive sequences of parameters as a single sequence of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710109362,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "nB3oBPJqCVkr"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "optimizer = torch.optim.Adam(itertools.chain(net.parameters(), embed.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyHhsIS1CVks"
   },
   "source": [
    "### Question 12: what is the role of \"log_softmax\" in the following cell? What is the role of \"nll_loss\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gD_Xw-GwXASf"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "\"log_softmax\" is computing the logarithm of the softmax of the neural network layer.\n",
    "\n",
    "\"nll_loss\" is the negative log likelihood loss.\n",
    "\n",
    "Let $f$ be a vector containing the class scores for a single example, that is, the output of the network. Thus $f_k$ is an element for a certain class $k$.\n",
    "\n",
    "We can then rewrite the softmax output as\n",
    "$$\n",
    "p_k=\\frac{e^{f_k}}{\\sum{j=1}^{K}e^{f_j}}\n",
    "$$\n",
    "where $K$ is the number of classes.\n",
    "\n",
    "The negative log-likelihood is\n",
    "$$\n",
    "L_i = -\\log(p_{y_i})\n",
    "$$\n",
    "where $y_i$ is the correct class index of input sample $i$.\n",
    "\n",
    "The loss $L_i$ is positive. It is minimum (equal to $0$) when $p_{y_i}=1$ (good classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710109362,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "6oTItpMDdNFU",
    "outputId": "b8dc5cd1-f964-458d-aa20-ff12d946e916"
   },
   "outputs": [],
   "source": [
    "# Just a cell to illustrate how nll_loss is working\n",
    "\n",
    "# input is of size N x C = 3 x 5\n",
    "# we have 5 classes\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 0, 4])\n",
    "output = F.nll_loss(F.log_softmax(input,1), target) # WARNING: logsoftmax is crucial!\n",
    "# The log in logsoftmax is clearly essential ; if we remove the log, it does not work anymore\n",
    "# You can check that by uncommenting the following line and the line Q=-P\n",
    "#output = F.nll_loss(F.softmax(input,1), target) \n",
    "print(output)\n",
    "print(input)\n",
    "P = F.softmax(input,1)\n",
    "print(P)\n",
    "Q = -torch.log(P)\n",
    "#Q = -P\n",
    "print(Q)\n",
    "(Q[0,target[0]]+Q[1,target[1]]+Q[2,target[2]])/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVcXjVEICVks"
   },
   "source": [
    "### Question 13: why do we compute the loss only for a subset of labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWJbdNFUgTvk"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "We compute the loss only for the labels we know in advance. The other labels are unknown (semi-supervised learning). The filtering is important to establish a relationship between all the nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUjLeiX3cBIW"
   },
   "source": [
    "### Question 14: when we are training the neural network, the inputs \"inputs\" are constant or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zho_dFMtcBIW"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "They are not constant. They depend on the embedding layer which is also learned during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1673710109569,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "G7R-_QkOSxbg",
    "outputId": "72731379-a612-4d52-9246-23d9ae1aab3b"
   },
   "outputs": [],
   "source": [
    "# Train the neural network and the embedding layer\n",
    "all_logits = []\n",
    "for epoch in range(50):\n",
    "    logits = net(G, inputs)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1) # the \"1\" indicates the dimension along which log_softmax will be computed.\n",
    "    # we compute loss for labeled nodes only\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels) # \"labels\" is a vector of integers (each integer corresponds to a class indentifier between 0 and K-1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mH9ZkiICVks"
   },
   "source": [
    "This is a rather toy example, so it does not even have a validation or test\n",
    "set. Instead, since the model produces an output feature of size 2 for each node, we can\n",
    "visualize by plotting the output feature in a 2D space.\n",
    "The following code animates the training process from initial guess\n",
    "(where the nodes are not classified correctly at all) to the end\n",
    "(where the nodes are linearly separable).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673710109569,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "v5TZKnlACVks"
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw(i):\n",
    "    cls1color = '#00FFFF'\n",
    "    cls2color = '#FF00FF'\n",
    "    pos = {}\n",
    "    colors = []\n",
    "    for v in range(34):\n",
    "        pos[v] = all_logits[i][v].numpy()\n",
    "        cls = pos[v].argmax()\n",
    "        colors.append(cls1color if cls else cls2color)\n",
    "    ax.cla()\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Epoch: %d' % i)\n",
    "    nx.draw_networkx(nx_G.to_undirected(), pos, node_color=colors,\n",
    "            with_labels=True, node_size=300, ax=ax)\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "fig.clf()\n",
    "ax = fig.subplots()\n",
    "draw(0)  # draw the prediction of the first epoch\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "executionInfo": {
     "elapsed": 19858,
     "status": "ok",
     "timestamp": 1673710129757,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "kvkF2ZrTCVkt",
    "outputId": "08b799df-3a26-47c5-bed4-6c9edc7cc0cb"
   },
   "outputs": [],
   "source": [
    "ani = animation.FuncAnimation(fig, draw, frames=len(all_logits), interval=200)\n",
    "from IPython.display import HTML\n",
    "# If 'ffmpeg' is not installed on your laptop, the following command fails\n",
    "# Just run this notebook on Google Colab to see the animation\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND6LZLiFcBIX"
   },
   "source": [
    "\n",
    "\n",
    "## Step 6: Create your own GCN layer\n",
    "--------------------------------------------------\n",
    "\n",
    "In the following cells, you will code your own GCN layer based on the famous message passing paradigm.\n",
    "This approach is especially relevant for large graphs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-PFNh6OCVkp"
   },
   "source": [
    "### Question 15: what is the main advantage of message-passing paradigm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms0j45rocBIX"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "Message-passing involvesd a message function defined on each edge to generate a â€œmessageâ€ \n",
    "by combining the edge feature with node features at its two ends.\n",
    "\n",
    "Then, an update function is defined on each node to update the node feature by aggregating \n",
    "its incoming messages using a reduce operation (sum, average, max, etc.). \n",
    "\n",
    "This way to ccommunicate between nodes by using the edges is well adapted to graphs, especially when the graph contains many nodes and edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSwVQEjPcBIX"
   },
   "source": [
    "#### Define the message and reduce function\n",
    "\n",
    "In DGL, the message functions are expressed as Edge UDFs (User Defined Function). \n",
    "Edge UDFs take in a single argument edges. It has three members src, dst, and data for accessing source node features, destination node features, and edge features. \n",
    "Here, the function computes messages only from source node features.\n",
    "\n",
    "Hence, by default, the messages come from the neighborhood of the nodes, i.e. they arrive via the 1-hop nodes connected via an edge.\n",
    "\n",
    "We first define the message and reduce functions. Since the aggregation on a node only involves summing over the neighborsâ€™ representations, we can simply use builtin functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qiw6BhCuCVkp"
   },
   "source": [
    "### Question 16: what is the goal of \"fn.copy_u\" and \"fn.sum\" in the next cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "getbfYJNcBIX"
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "dgl.function.copy_u(u, out) is a builtin message function that computes message using source node feature \"u\" is the source node feature (wrt to the edge) and \"out\" is the message name.\n",
    "The message are stored in a \"mailbox\" associated to the node.\n",
    "\n",
    "See more details on https://docs.dgl.ai/en/latest/guide/message-api.html?highlight=mailbox\n",
    "\n",
    "dgl.function.sum is a builtin reduce function that aggregates all messages by sum. \n",
    "The result is stored in the node feature \"h\"\n",
    "Generally the messages come from the neighborhood of the node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710129757,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "HpWGgbJccBIX"
   },
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "gcn_message = fn.copy_u(u='h', out='m') \n",
    "\n",
    "gcn_reduce = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-QLxs5GcBIX"
   },
   "source": [
    "We then proceed to define the GCNLayer module. A GCNLayer essentially performs message passing on all the nodes then applies a fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710129757,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "fGuW9QRecBIX"
   },
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        # Creating a local scope so that all the stored ndata and edata\n",
    "        # (such as the `'h'` ndata below) are automatically popped out\n",
    "        # when the scope exits.\n",
    "        #\n",
    "        # Note that an input is considered as a node feature.\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = feature\n",
    "            # \"update_all\" collect features from source nodes and aggregate them in destination nodes\n",
    "            g.update_all(gcn_message, gcn_reduce)\n",
    "            h = g.ndata['h']\n",
    "            return self.linear(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZheTH_RcBIX"
   },
   "source": [
    "### Question 17: create a class GCNmp similar to the previous class GCN which is based on the GCNlayer classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710129758,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "G6uKpCU_cBIY"
   },
   "outputs": [],
   "source": [
    "# Fill in the cell\n",
    "\n",
    "# Define a 2-layer GCN model based on GCNlayer\n",
    "# GCNmp with mp = message-passing\n",
    "class GCNmp(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes):\n",
    "        super(GCNmp, self).__init__()\n",
    "        self.gcn1 = GCNLayer(in_feats, hidden_size)\n",
    "        self.gcn2 = GCNLayer(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.gcn1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gcn2(g, h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOhqqYfVcBIY"
   },
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673710129758,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "a_8nLa1RcBIY"
   },
   "outputs": [],
   "source": [
    "netmp = GCNmp(embed_dim, hidden_dim, 2)\n",
    "\n",
    "embedmp = nn.Embedding(Nnodes, embed_dim)  \n",
    "inputs_mp = embedmp.weight\n",
    "\n",
    "optimizer = torch.optim.Adam(itertools.chain(netmp.parameters(), embedmp.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1673710130134,
     "user": {
      "displayName": "Lionel Fillatre",
      "userId": "14463393848879581998"
     },
     "user_tz": -60
    },
    "id": "AeTUiWRYcBIY",
    "outputId": "e483c943-befa-471f-d0a4-ac733a3a2c78"
   },
   "outputs": [],
   "source": [
    "all_logits = []\n",
    "for epoch in range(30):\n",
    "    logits = netmp(G, inputs_mp)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
